\section{Optimization System}
\label{optimization}
This section will discuss the alternative proposal for arterial optimization, which was developed in response to DOGS.

\subsection{Coordination}
\label{coordination}
Coordination along an arterial is fundamental in signal optimization. The ideal situation for road users is the \textit{green wave}, where upon arrival to the next intersection there will always be a green light.

Contemporary car engines consume less fuel in general when they are allowed to run at a constant RPM level so the travel experience as well as emmission levels are improved under coordination.

There are also security aspects which indicate that coordination and green waves are desirable since the human eye has difficulty in observing acceleration and deceleration.

In one-way coordination a signal controller emits a platoon of vehicles over a period of time, say from $t_1$ to $t_2$, where $T_g = t_2 - t_1$ is indicative of the number of vehicles that need to pass. To avoid stopping these vehicles at the next signal the same amount of green time, $T_g$ must be given to the approaching platoon only \textit{offset} in time by $o$ time units to represent the travel time of the platoon from one signal to the next. 

In fact, due to \textit{platoon dispersion} SEE XXX XXX, which depend mainly on the intersignal distance and speeds, more than $T_g$ green time must be allotted to the stage of the downstream signal. It is also due to platoon dispersion that coordination is only relevant for signals which are relatively close. Practical experience from DRD indicate that the distance should not exceed 800-900 m. 

In perfect two-way coordination between two intersections the leading vehicles in platoons of traffic in either direction must experience that the next signal switch to green before they reach the area in which they decide to brake for red.

In a common cycle-time based system \cite{coord} gives us:

$$o = n \cdot \frac{C}{2}$$

Where $o$ is the travel time between the intersections, which is assumed to be the same in both directions, $C$ is the cycle time and $n$ is an integer.

The travel time is calculated as $o = L / v$ where $L$ is the distance and $v$ is the speed by which road users travel between the intersections. By insertion we get:

$$C = 2 \cdot \frac{L}{n \cdot v}$$

This equation is quite constrained, however. For cycle time we require that is lies within a span of about 60 til 120 seconds based on practical experiences. If the cycle time is less stage lengths become too short to reach past the queue startup delays (about 4 vehicles), if more the minor roads experience long delays and pedestrians and bicyclists may start to cross the road before the signal is green.

In addition green waves usually span over more than two intersections with may have different distances and average speeds between them, all this making it hard or impossible to find an integer $n$. Thus green waves are most obvious in one, main direction. It is possible to affect the average speeds between intersections by changing the allowed speed-signs. If this is not sufficient one might accept that the green wave is not perfect by, for instance, prioritizing one direction over the other.

Priority can be given entirely to one direction or distributed by some weight, for instance based on the ratio of traffic in each direction. An obvious choice for the first option would be for an arterial with traffic between some suburbs and a major city. In the morning full priority should be given in the direction towards the city when people go to work and opposite in the afternoon. A third alternative is to a perfect progression band in one direction for a some ratio of time, corresponding to the ratios of traffic in either direction.
For ring road 3, which was simulated in this project, there is no clear distinction between the direction of morning and afternoon traffic (see Section \ref{data}) and a solution which weights the green wave quality according to direction ratio. 

The distance between one signal head (intersection) and the next can be extracted from the Vissim network file in both directions and is static. The signal heads for both directions of the arterial are marked using a naming convention similar to the one mentioned in Section \ref{routefractions} only less information is required since the relation of the head to its signal controller can be deduced directly from the network file. Further details on this process can be read in Section \ref{signal_details}.

For travel times (which is a key component in finding a proper offset) it is possible to rely on the speed limitations / free flow speeds for offset calculation, however under congestion speeds will decrease causing the travel times to increase. A better solution is to continously inspect the smoothened travel times which are inserted for each stretch. 

\subsection*{Manipulating speed}
Except on sundays and in parts of western Denmark, most motorists will obey the speed signs. The travel time between intersections, which largely determines the offset, could then be increased or decreased by changing the speed signs.

Some considerations should be made in this respect. For instance we must ensure that the speeds do not divert too much from the norm of the relevant type of road. In addition the number of speed changes, which a motorist travelling throughout the arterial experience, must be minimized. And if speed changes do occur, it is a good idea to keep them small so that the speeds don't go from 50 to 70 from one stretch of road to the next.

From a security perspective it might seem risky to not persist a common speed level through the artery. But considering that a change of speed might improve the quality of a green wave, this problem can be negated. This also applies to the additional acceleration and deceleration since, if a green wave does not exist the vehicles must be stopped altogether at the red light causing even more acceleration.

The current infrastructure on O3 does not offer this fine-grained level of adjustment but electronic speed signs are common practice nowadays and is, for instance, used on the almost-parallel motorring 3 to smoothen out queues.

\subsection{Metaheuristic Search}
DRD has traditionally used TRANSYT to obtain coordination but often it is necessary to manually adjust the offsets in order to obtain a good two-way coordination. 

This manual process involves creating good two-way green waves by compromise, which could be either some sacrifice in the quality of the green waves. 

In this project the green wave concept has been formalized so that it is possible to evaluate a proposal for offsets. This opens up for the application of a metaheuristic search procedure.

In this first cycle-based approach the variable to be optimized is, of course, the offset for each signal controller. The signal controllers themselves operate under cyclic plans which are shifted in time according to the chosen offset. In addition the allowed speeds from a signal to the next may be changed to obtain better results.

\label{eval_coord}
For evaluation of a \textit{coordination} between $sc_1$ and $sc_2$ (directed) in the context of a time horizon $H = h_{min} .. h_{max}$ we examine each green band, which is emitted from $sc_1$. Given the distance and chosen speed from $sc_1$ to $sc_2$ we can count how many seconds worth of green band, which is not being let through by $sc_2$. The band from $sc_1$ may be cut in three ways, if $sc_2$ does not provide a green light, when the band reaches it 1) completely ie. there is a red light for the duration of the band 2) the front is cut off 3) the tail is cut off.

Obviously the first option is worst as all vehicles must halt. Second is the cutting of the leading vehicles, since they must brake or come to a halt, effectively halting the entire platoon. Least intrusive is the cutting of the tail, since then, at least, parts of the platoon actually experienced a green wave when travelling between $sc_1$ and $sc_2$.

\subsection*{Simulated Annealing}
In this section I describe the metaheuristic search routing, which was chosen: Simulated Annealing (SA). 
SA is a \textit{hill-climber} with the ability to escape from local optima ie. jump to another hill-top.

What this means is that SA performs a randomized, converging search in the entire search space (for offsets that is each combination of $N \bmod C$ over the intersections) looking for the possible best set of offsets without getting stuck with the \textit{first-and-best} solution it encounters.

The initial solution is chosen so that all offsets are zero. SA then works its way toward a better solution by examining neighbor solutions to the current one. A neighbor solution is found by incrementing or decrementing a single offset in the current solution or changing the allowed speed between the intersections by 5$km/h$.

The solutions to offsets are evaluated and compared in the context of the network and, if a neighbor is found to be better than the best solution found so far, it is adopted as the new \textit{encumbent}. If the neighbor was not better it should be thrown away, but here SA avoids being caught in a local optima by \textit{with some probability} keeping the neighbor solution regardless and work on from there. This probability will decrease as the search progress and so it is subject to tuning.

Generally metaheuristics give no guarantee that an optimum solution will be found, but with proper tuning and fast data structures, so that at least a couple of hundred solutions can be tested per second, it will generally yield good solutions. The strengths of metaheuristics are that they can easily support any kind of constraint, take advantage of the structure of the problem and run in O([insert seconds here]) ie. the running time is bounded by the time available.

\subsection*{Data Structures}
In this project I have developed data structures, which are fast enough to generate the necessary iterations per second and can be used in various metaheuristic search schemes, not just simulated annealing.

The keys to speed in metaheuristic search are \textit{delta-evaluation} and to avoid \textit{object instantiation}.

\subsubsection*{Delta-evaluation}
To evaluate a solution for offsets for sequentially adjacent signal controllers $sc_1$ to $sc_n$ we evaluate, in accordance to description in Section \ref{eval_coord}, each coordination $(sc_1,sc_2)$, $(sc_2,sc_1)$\footnote{Coordinations between adjacent signal controllers need not be symmetrical. For instance there might be a longer way in one direction that the other or, more likely, different \textit{speeds} might be allowed} and so forth. This gives us a value for each coordination and we then perform some kind of aggregation in order to obtain a single figure, the solution value.

Every time a neighbor solution is generated we normally immediately want to evaluate it as well. This can be done by going through the routine described above, but we can also use delta-evaluation to speed up the evaluation, if we have information on the structure of the problem.

A change in the offset of signal controller $sc_i$ will affect the coordinations between $sc_{i-1}$ and $sc_{i}$ and also between $sc_{i}$ and $sc_{i+1}$. Since we didn't change the offset $sc_{i-1}$ or $sc_{i+1}$ or any other offset, all coordinations but those mentioned will remain just as good - or bad - as before the offset change for $sc_i$. This is illustrated in Figure \ref{fig:delta_eval}.

\begin{figure}[!ht]
\begin{center}
\includegraphics[scale=0.3]{delta_eval.png} 
\end{center}
\caption{Local nature of coordinations. This illustrates the quality of coordinations between three signal controllers before and after changing the offset of the middle controller. Notice that the coordinations between the outer controllers and $sc_{i-2}$ and $sc_{i+2}$ remain the same.}
\label{fig:delta_eval}
\end{figure}

So, rather than evaluating every coordination again we may safely assume that only coordinations $(sc_{i-1},sc_{i})$, $(sc_{i-1},sc_{i})$ and $(sc_{i},sc_{i+1})$, $(sc_{i+1},sc_{i})$ need to be reevaluated. 

We now need only to evaluate at most four coordinations\footnote{Changing offsets for controllers in the ends of the arterial will only change the value of two coordinations.} to obtain the neighbor solution value. In total there are $2\cdot (n-1)$ coordinations to evaluate since each signal controller has an outgoing coordination in each direction except at the ends, which have only one. Thus we exchange a linearly growing reevaluation time (in the number of signal controllers) for a constant one and rough tests have shown that, even for small networks, the savings are in excess of a factor two, in spite of the extra overhead due to bookkeeping.

\subsubsection*{Neighbor solutions}
In previous studies of metaheuristics, where the object oriented programming model was completely adopted, it was found that the overhead of object instantiation, whenever a neighbor solution was generated, would result in tremendous time consumption. 

Instead I have minimized the need for copying information from a solution to its neighbor by introducing the dual methods \verb|change| and \verb|undo_changes|. The purpose of these methods is to allow a solution to temporarily take the form of its neighbor and switch back to its former self, if requested. 
When the metaheuristic runs it will constantly ask for neighbor solutions but throw away most of them. This approach avoids much copying of solution attributes and at the same time the details of the switching of identify are relayed to the solution object.

\subsubsection*{Bookkeeping outline}
The \verb|change| and \verb|undo_changes| methods are closely integrated with delta-evaluation. The initial solution obviously cannot be delta-evaluated so, during full evaluation, the \textit{contribution} from each coordination is noted. 

When \verb|change| is called a signal controller whose offset to change is chosen as well as a new offset value. Next we find the affected coordinations and update the value of the solution by swapping the old contributions with the new ones, when evaluated under the changed offset.

We must be ready to undo the changes we just made, so we track all these changes: which offset we changed and by how much as well as the previous contributions from the affected coordinations.

The extra time spent on bookkeeping is bounded by the number of affected coordinations, as explained previously and does increase the complexity of the codes by a great amount.

\subsection{Stage-based signals}
Assuming fixed signal plans we have expressions for the offset and cycle time which causes coordination. Fixed signal plans are identical for each cycle iteration. It is possible to include green time extensions such as the ones used for bus priority but it is always necessary to take the seconds from some other stage. Likewise with stage skipping, you must always "spend" $C$ cycle seconds.

For stage based signals the plans cannot be written down in advance in terms of $C$ but rather must be defined dynamically on the basis of \textit{signal rules} and the measured traffic conditions. For coordination the rule is:

\begin{quote}
Whenever the arterial stage for a signal is active from $t_1$ to $t_2$ the arterial stage of the downstream signal must be active from $t_1 + o$ to $t_2 + o$.
\end{quote}

